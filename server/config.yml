usage_loading:

  db:
    # Configure HyperSQL to use in-memory DB
    mode: memory

    # Alternatively could configure HyperSQL to use disk based
    # DB instead.
    #mode: disk
    #path: /path/to/my/db

  data:
    # Get usage data from local disk
    mode: local

    # Get usage data from Hadoop
    # mode: hadoop

    # When using local disk for source data
    local:
      # "ant test-data" generates data matching this pattern
      file_pattern: data/usage/**/*.avro 

      # How often to check for new aggregated usage data to load.
      refresh_in_mins: 15

    # When using Hadoop for source data
    hadoop:

      # How often to check for new aggregated usage data to load.
      refresh_in_mins: 15

      # Glob pattern to load usage files from HDFS.
      file_pattern: hdfs://namenode.url.com:port/path/to/root/usage-per-hour/*/*/*/*.avro

      # Directories containing JARs to be added to the classpath.
      libs:
        - /hadoop/binaries
        - /hadoop/binaries/lib

      # Where to find the Hadoop configuration.  This will be added to the classpath.
      conf_dir: /hadoop/conf

      # When connecting to a secure Hadoop cluster these lines must be used to login.
      #secure:
      #  principal: username
      #  keytab: /home/username/username.keytab
